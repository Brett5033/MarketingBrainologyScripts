{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.signal import welch\n",
    "import matplotlib.dates as mdates\n",
    "from mpl_toolkits.axes_grid1 import host_subplot\n",
    "import mpl_toolkits.axisartist as AA\n",
    "import matplotlib.animation as animation\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from datetime import datetime, timedelta\n",
    "import threading\n",
    "import time\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "import BrainBitPython.BrainBitDemo.neuro_impl.emotions_bipolar_controller\n",
    "import BrainBitPython.BrainBitDemo.neuro_impl.emotions_monopolar_controller\n",
    "import BrainBitPython.BrainBitDemo.neuro_impl.spectrum_controller\n",
    "\n",
    "from BrainBitPython.BrainBitDemo.neuro_impl.emotions_bipolar_controller import EmotionBipolar\n",
    "from BrainBitPython.BrainBitDemo.neuro_impl.emotions_monopolar_controller import EmotionMonopolar\n",
    "from BrainBitPython.BrainBitDemo.neuro_impl.spectrum_controller import SpectrumController\n",
    "\n",
    "importlib.reload(BrainBitPython.BrainBitDemo.neuro_impl.emotions_bipolar_controller)\n",
    "importlib.reload(BrainBitPython.BrainBitDemo.neuro_impl.emotions_monopolar_controller)\n",
    "importlib.reload(BrainBitPython.BrainBitDemo.neuro_impl.spectrum_controller)\n",
    "\n",
    "import hrvanalysis\n",
    "\n",
    "mpl.rcParams['animation.ffmpeg_path'] = r'C:\\Program Files\\FFmpeg\\bin\\ffmpeg.exe'\n",
    "\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running Procedure\n",
    "\n",
    "# Add data csv's to the folders in 'Data'\n",
    "\n",
    "# See Options Below\n",
    "# Setup however require for the current data\n",
    "\n",
    "# Make sure you see 'Python 3.X.X' in the top right of this window\n",
    "# If it says 'select kernal' or smth, click it and select python\n",
    "\n",
    "# See Toolbar at the top of the window (Code, Markdown, Run All, Restart)\n",
    "# Start each run by hitting 'Restart'\n",
    "# If anything gives an error, try hitting restart first (confirm restart if needed)\n",
    "\n",
    "# Hit 'Run All'\n",
    "\n",
    "# Runs can probably take up to a few minutes depending on the volume of data\n",
    "# You can see how it has completed on each code block's bottom left with the check mark and time it took to run\n",
    "\n",
    "# Each blocks output will show below itself, but if you just need the final video, it will automatically show up in the Data/Exports folder with the name you gave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Options\n",
    "\n",
    "# How much time should be shown at any one time on the chart (Default 60 seconds)\n",
    "LiveChartWindowSizeInSeconds = 60\n",
    "\n",
    "# Heart Rate File in the Data/Watch/ folder, no extention needed (ex: 'Checkme O2 Max _20250716192137')\n",
    "HeartRate_CSVFileName = 'Checkme O2 Max _20250716192137'\n",
    "\n",
    "# The interval timing for the Heart Rate & EEG Data (Every _ seconds, default 2 seconds)\n",
    "MeasuringIntervalInSeconds = 2\n",
    "\n",
    "# Export timespans, This lets you set when you want the export to start in terms of UTC time (ex. to match up with eeg recording) and how long to run it for\n",
    "# Workflow for this would be get the EEG startime from OBS recording, and total run duration, and then export a heartrate video to match perfectly  \n",
    "\n",
    "ExportFolder = True\n",
    "\n",
    "ExportWholeDuration = True\n",
    "\n",
    "MirrorInputFileName = True\n",
    "\n",
    "# Time that you want the export to start at, make sure it is UTC time (ex: '2025-07-21 23:45:00')\n",
    "ExportWindowStartTime = '2025-07-16 19:21:37'\n",
    "\n",
    "# The (Minutes:Seconds) duration you want the export to be\n",
    "ExportWindowDuration = '20:00'\n",
    "\n",
    "# Export File Name for Video Recording of Chart Animation (ex: 'Brett Chart')\n",
    "ChartExportFileName = \"Brett Chart\"\n",
    "\n",
    "FolderName = 'Tuesday July 22 2025 Matthew'\n",
    "\n",
    "WordDateFormat = False\n",
    "\n",
    "# Width and Height for the Video, more for getting the ratio of W/H (Ex. Width: 15, Height: 5)\n",
    "ExportWidth = 15\n",
    "ExportHeight = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Options for EEG Data\n",
    "\n",
    "# EEG File in the Data/EEG/ folder, no extention needed (ex: '15.07.2025_17-42 - 15.07.2025_17-42')\n",
    "EEG_CSVFileName = '15.07.2025_17-42 - 15.07.2025_17-42'\n",
    "\n",
    "# Start time for the EEG Data, make sure it is UTC time (ex: '2025-07-21 23:45:00')\n",
    "EEG_UTCStartTime = '2025-07-21 23:45:00'\n",
    "\n",
    "# Not fully implemented yet\n",
    "EEG_Enabled = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BuildHeartRateDF(filePath):    \n",
    "    rawDf = pd.read_csv(filePath)\n",
    "\n",
    "    # Convert Time column to datetime\n",
    "    rawDf['Time'] = pd.to_datetime(rawDf['Time'], format='%H:%M:%S %b %d %Y' if WordDateFormat else '%H:%M:%S %d/%m/%Y')\n",
    "\n",
    "    df = None\n",
    "    if ExportWholeDuration:\n",
    "        df = rawDf.copy()\n",
    "    else:\n",
    "        # Convert duration to timedelta\n",
    "        minutes, seconds = map(int, ExportWindowDuration.split(\":\"))\n",
    "        duration = timedelta(minutes=minutes, seconds=seconds)\n",
    "\n",
    "        ExportWindowStartTimeDT = datetime.strptime(ExportWindowStartTime, \"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "        ExportWindowEndTime = ExportWindowStartTimeDT + duration\n",
    "\n",
    "        filtered_df = rawDf[(rawDf['Time'] >= ExportWindowStartTimeDT) & (rawDf['Time'] <= ExportWindowEndTime)].copy()\n",
    "\n",
    "        full_time_index = pd.date_range(start=ExportWindowStartTimeDT, end=ExportWindowEndTime, freq='2S')\n",
    "\n",
    "        # Set Timestamp as index\n",
    "        filtered_df.set_index('Time', inplace=True)\n",
    "\n",
    "        # Reindex to full time range\n",
    "        filled_df = filtered_df.reindex(full_time_index)\n",
    "\n",
    "        # Reset index and rename\n",
    "        filled_df.reset_index(inplace=True)\n",
    "        filled_df.rename(columns={'index': 'Time'}, inplace=True)\n",
    "        filled_df.fillna(0, inplace=True)\n",
    "\n",
    "        df = filled_df.copy()\n",
    "\n",
    "    df.set_index('Time', inplace=True)\n",
    "\n",
    "    # Remove non-numeric pulse entries if needed\n",
    "    df = df[df['Pulse Rate'] != '--'].copy()\n",
    "    df['Pulse Rate'] = pd.to_numeric(df['Pulse Rate'], errors='coerce')\n",
    "    df.dropna(subset=['Pulse Rate'], inplace=True)\n",
    "\n",
    "    # Convert BPM to RR intervals in milliseconds\n",
    "    # RR(ms) = (60 / HR)\n",
    "    df['RR'] = 60 * 1000 / df['Pulse Rate']\n",
    "\n",
    "    def compute_rmssd(rr_intervals):\n",
    "        diffs = np.diff(rr_intervals)\n",
    "        squared_diffs = diffs ** 2\n",
    "        return np.sqrt(np.mean(squared_diffs))\n",
    "\n",
    "    # 10-point rolling RMSSD (adjust based on sampling rate)\n",
    "    df['RMSSD'] = df['RR'].rolling(window=10).apply(compute_rmssd, raw=True)\n",
    "\n",
    "    bin_size = timedelta(seconds=30)\n",
    "    df['RMSSD_30s'] = (\n",
    "        df.groupby(pd.Grouper(freq='30s'))['RR']\n",
    "        .transform(lambda x: compute_rmssd(x.values))\n",
    "    )\n",
    "\n",
    "    df.reset_index(inplace=True)\n",
    "\n",
    "    average_rmssd = df['RMSSD'].mean()\n",
    "    df['Above Avg HRV'] = df['RMSSD'] > average_rmssd\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateHeartRateExport(df, exportName):\n",
    "    # Create triple y-axis layout\n",
    "    fig = plt.figure(figsize=(ExportWidth, ExportHeight))\n",
    "    host = host_subplot(111, axes_class=AA.Axes)\n",
    "    plt.subplots_adjust(left=0.4, right=0.5)\n",
    "\n",
    "    par3 = host.twinx() \n",
    "    par1 = host.twinx()      # Right axis for Heart Rate\n",
    "    par2 = host.twinx()      # Motion layer\n",
    "    \n",
    "\n",
    "    # üìå Offset heart rate axis further to the right\n",
    "    par1.axis[\"right\"].toggle(all=True)\n",
    "    par2.axis[\"right\"] = par2.get_grid_helper().new_fixed_axis(loc=\"right\", axes=par2, offset=(0, 0))\n",
    "    par2.axis[\"right\"].toggle(all=True)\n",
    "\n",
    "    par3.axis[\"right\"].toggle(all=True)\n",
    "    par3.axis[\"right\"] = par3.get_grid_helper().new_fixed_axis(loc=\"left\", axes=par3, offset=(0, 0))\n",
    "\n",
    "    # ‚è∞ Format x-axis ticks\n",
    "    host.xaxis.set_major_formatter(mdates.DateFormatter('%H:%M:%S'))\n",
    "\n",
    "    # üü¶ Plot RMSSD on left y-axis\n",
    "    p1, = host.plot(df['Time'], df['RMSSD'], color='steelblue', label='HRV (RMSSD)', linewidth=2)\n",
    "    host.axhline(df['RMSSD'].mean(), color='gray', linestyle='--', label='Average RMSSD')\n",
    "    host.set_ylabel('HRV (ms)', color='steelblue')\n",
    "    host.tick_params(axis='y', labelcolor='steelblue')\n",
    "\n",
    "    p4, = par3.plot(df['Time'], df['RMSSD_30s'], color='cyan', label='RMSSD_30s', alpha=1, linewidth=1)\n",
    "    par3.axis[\"right\"].label.set_visible(False)\n",
    "    par3.axis[\"right\"].major_ticklabels.set_visible(False)\n",
    "    par3.axis[\"right\"].major_ticks.set_visible(False)\n",
    "\n",
    "    # üî¥ Heart Rate on second y-axis\n",
    "    p2, = par1.plot(df['Time'], df['Pulse Rate'], color='crimson', label='Heart Rate (BPM)', alpha=1, linewidth=1)\n",
    "    par1.set_ylabel('Heart Rate (BPM)', color='crimson')\n",
    "    par1.tick_params(axis='y', labelcolor='crimson')\n",
    "\n",
    "    # üüß Motion as third line without visible axis\n",
    "    p3, = par2.plot(df['Time'], df['Motion'], color='darkorange', label='Motion', alpha=0.5, linewidth=1)\n",
    "    par2.axis[\"right\"].label.set_visible(False)\n",
    "    par2.axis[\"right\"].major_ticklabels.set_visible(False)\n",
    "    par2.axis[\"right\"].major_ticks.set_visible(False)\n",
    "\n",
    "    \n",
    "\n",
    "    # üß≠ Legend\n",
    "    host.legend(loc='upper left')\n",
    "    plt.title('HRV (RMSSD) with Heart Rate and Motion Overlay')\n",
    "    plt.tight_layout(pad=2.0)\n",
    "    #plt.show()\n",
    "\n",
    "    # Calculate static limits based on full dataset\n",
    "    rmssd_min, rmssd_max = df['RMSSD'].min() - 1, df['RMSSD'].max() + 1\n",
    "    pulse_min, pulse_max = df['Pulse Rate'].min() - 1, df['Pulse Rate'].max() + 1\n",
    "    motion_min, motion_max = df['Motion'].min() - 1, df['Motion'].max() + 1\n",
    "\n",
    "    # Apply fixed limits to each axis\n",
    "    host.set_ylim(rmssd_min, rmssd_max)\n",
    "    par3.set_ylim(rmssd_min, rmssd_max)\n",
    "    par1.set_ylim(pulse_min, pulse_max)\n",
    "    par2.set_ylim(motion_min, motion_max)\n",
    "\n",
    "    # Animation update function\n",
    "    def update(frame):\n",
    "        start_time = df['Time'].iloc[0] + pd.Timedelta(seconds=MeasuringIntervalInSeconds * frame)\n",
    "        end_time = start_time + pd.Timedelta(seconds=LiveChartWindowSizeInSeconds)\n",
    "        window_df = df[(df['Time'] >= start_time) & (df['Time'] <= end_time)]\n",
    "\n",
    "        if window_df.empty:\n",
    "            return p1, p4, p2, p3\n",
    "\n",
    "        # Update plot data\n",
    "        p1.set_data(window_df['Time'], window_df['RMSSD'])\n",
    "        p2.set_data(window_df['Time'], window_df['Pulse Rate'])\n",
    "        p3.set_data(window_df['Time'], window_df['Motion'])\n",
    "        p4.set_data(window_df['Time'], window_df['RMSSD_30s'])\n",
    "\n",
    "        # Adjust x-axis\n",
    "        host.set_xlim(start_time, end_time)\n",
    "\n",
    "        return p1, p4, p2, p3\n",
    "\n",
    "    print(f'Creating Animation with Window Size: {LiveChartWindowSizeInSeconds}sec and Data Increments of {MeasuringIntervalInSeconds}sec. Video Length: {len(df) * MeasuringIntervalInSeconds / 60.0:.2f}min')\n",
    "\n",
    "    # Create animation\n",
    "    ani = FuncAnimation(fig, update, frames=len(df), interval=MeasuringIntervalInSeconds * 1000)\n",
    "    #plt.show()\n",
    "\n",
    "    # Flag to control the loop\n",
    "    exporting = True\n",
    "\n",
    "    def show_progress():\n",
    "        max_width = len(\"Generating...\")  # fixed width to overwrite trailing dots\n",
    "        dots = 0\n",
    "        while exporting:\n",
    "            message = \"Generating\" + \".\" * (dots % 4)\n",
    "            padded = message.ljust(max_width)  # pad with spaces\n",
    "            print(f\"\\r{padded}\", end=\"\", flush=True)\n",
    "            dots += 1\n",
    "            time.sleep(0.5)\n",
    "\n",
    "    # Start background thread\n",
    "    progress_thread = threading.Thread(target=show_progress)\n",
    "    progress_thread.start()\n",
    "    \n",
    "    ani.save(f'Data/Exports/{exportName}.mp4', writer='ffmpeg', fps=1.0 / MeasuringIntervalInSeconds)\n",
    "\n",
    "    # Stop the progress indicator\n",
    "    exporting = False\n",
    "    progress_thread.join()\n",
    "\n",
    "    print(f'\\nAnimation Exported to: {exportName}.mp4')\n",
    "\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "time data \"09:49:44 22/07/2025\" doesn't match format \"%H:%M:%S %b %d %Y\", at position 0. You might want to try:\n    - passing `format` if your strings have a consistent format;\n    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[98]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     12\u001b[39m         file_path = os.path.join(folderPath, filename)\n\u001b[32m     13\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m os.path.isfile(file_path) \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33m.csv\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m filename:\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m             df = \u001b[43mBuildHeartRateDF\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m             CreateHeartRateExport(df, os.path.join(FolderName, filename.removesuffix(\u001b[33m'\u001b[39m\u001b[33m.csv\u001b[39m\u001b[33m'\u001b[39m)))\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     17\u001b[39m     \u001b[38;5;66;03m# Run Single File\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[96]\u001b[39m\u001b[32m, line 5\u001b[39m, in \u001b[36mBuildHeartRateDF\u001b[39m\u001b[34m(filePath)\u001b[39m\n\u001b[32m      2\u001b[39m rawDf = pd.read_csv(filePath)\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Convert Time column to datetime\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m rawDf[\u001b[33m'\u001b[39m\u001b[33mTime\u001b[39m\u001b[33m'\u001b[39m] = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_datetime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrawDf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mTime\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m%\u001b[39;49m\u001b[33;43mH:\u001b[39;49m\u001b[33;43m%\u001b[39;49m\u001b[33;43mM:\u001b[39;49m\u001b[33;43m%\u001b[39;49m\u001b[33;43mS \u001b[39;49m\u001b[33;43m%\u001b[39;49m\u001b[33;43mb \u001b[39;49m\u001b[38;5;132;43;01m%d\u001b[39;49;00m\u001b[33;43m \u001b[39;49m\u001b[33;43m%\u001b[39;49m\u001b[33;43mY\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m df = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ExportWholeDuration:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\tools\\datetimes.py:1072\u001b[39m, in \u001b[36mto_datetime\u001b[39m\u001b[34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[39m\n\u001b[32m   1070\u001b[39m         result = arg.map(cache_array)\n\u001b[32m   1071\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1072\u001b[39m         values = \u001b[43mconvert_listlike\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1073\u001b[39m         result = arg._constructor(values, index=arg.index, name=arg.name)\n\u001b[32m   1074\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, (ABCDataFrame, abc.MutableMapping)):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\tools\\datetimes.py:435\u001b[39m, in \u001b[36m_convert_listlike_datetimes\u001b[39m\u001b[34m(arg, format, name, utc, unit, errors, dayfirst, yearfirst, exact)\u001b[39m\n\u001b[32m    433\u001b[39m \u001b[38;5;66;03m# `format` could be inferred, or user didn't ask for mixed-format parsing.\u001b[39;00m\n\u001b[32m    434\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mformat\u001b[39m != \u001b[33m\"\u001b[39m\u001b[33mmixed\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m435\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_array_strptime_with_fallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mutc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexact\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    437\u001b[39m result, tz_parsed = objects_to_datetime64(\n\u001b[32m    438\u001b[39m     arg,\n\u001b[32m    439\u001b[39m     dayfirst=dayfirst,\n\u001b[32m   (...)\u001b[39m\u001b[32m    443\u001b[39m     allow_object=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    444\u001b[39m )\n\u001b[32m    446\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m tz_parsed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    447\u001b[39m     \u001b[38;5;66;03m# We can take a shortcut since the datetime64 numpy array\u001b[39;00m\n\u001b[32m    448\u001b[39m     \u001b[38;5;66;03m# is in UTC\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\tools\\datetimes.py:469\u001b[39m, in \u001b[36m_array_strptime_with_fallback\u001b[39m\u001b[34m(arg, name, utc, fmt, exact, errors)\u001b[39m\n\u001b[32m    458\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_array_strptime_with_fallback\u001b[39m(\n\u001b[32m    459\u001b[39m     arg,\n\u001b[32m    460\u001b[39m     name,\n\u001b[32m   (...)\u001b[39m\u001b[32m    464\u001b[39m     errors: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m    465\u001b[39m ) -> Index:\n\u001b[32m    466\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    467\u001b[39m \u001b[33;03m    Call array_strptime, with fallback behavior depending on 'errors'.\u001b[39;00m\n\u001b[32m    468\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m469\u001b[39m     result, tz_out = \u001b[43marray_strptime\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfmt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexact\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexact\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mutc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mutc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    470\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m tz_out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    471\u001b[39m         unit = np.datetime_data(result.dtype)[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/tslibs/strptime.pyx:501\u001b[39m, in \u001b[36mpandas._libs.tslibs.strptime.array_strptime\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/tslibs/strptime.pyx:451\u001b[39m, in \u001b[36mpandas._libs.tslibs.strptime.array_strptime\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/tslibs/strptime.pyx:583\u001b[39m, in \u001b[36mpandas._libs.tslibs.strptime._parse_with_format\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mValueError\u001b[39m: time data \"09:49:44 22/07/2025\" doesn't match format \"%H:%M:%S %b %d %Y\", at position 0. You might want to try:\n    - passing `format` if your strings have a consistent format;\n    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this."
     ]
    }
   ],
   "source": [
    "if(ExportFolder):\n",
    "    # Run Folder Batch\n",
    "\n",
    "    folderPath = f'Data/Watch/{FolderName}'\n",
    "\n",
    "    exportFolderPath = f'Data/Exports/{FolderName}'\n",
    "    if not os.path.exists(exportFolderPath):\n",
    "        os.makedirs(exportFolderPath)\n",
    "\n",
    "\n",
    "    for filename in os.listdir(folderPath):\n",
    "        file_path = os.path.join(folderPath, filename)\n",
    "        if os.path.isfile(file_path) and '.csv' in filename:\n",
    "            df = BuildHeartRateDF(file_path)\n",
    "            CreateHeartRateExport(df, os.path.join(FolderName, filename.removesuffix('.csv')))\n",
    "else:\n",
    "    # Run Single File\n",
    "    exportName = HeartRate_CSVFileName if MirrorInputFileName else ChartExportFileName\n",
    "\n",
    "    file_path = f'Data/Watch/{HeartRate_CSVFileName}.csv'\n",
    "\n",
    "    df = BuildHeartRateDF(file_path)\n",
    "    CreateHeartRateExport(df, exportName)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(EEG_Enabled):\n",
    "    eeg_df = pd.read_csv(f'Data/EEG/{EEG_CSVFileName}.csv')\n",
    "\n",
    "    #O1,O2,T3,T4,O1_T3,O2_T4\n",
    "    eeg_df['O1'] = pd.to_numeric(eeg_df['O1'], errors='coerce')\n",
    "    eeg_df['O2'] = pd.to_numeric(eeg_df['O2'], errors='coerce')\n",
    "    eeg_df['T3'] = pd.to_numeric(eeg_df['T3'], errors='coerce')\n",
    "    eeg_df['T4'] = pd.to_numeric(eeg_df['T4'], errors='coerce')\n",
    "    eeg_df['O1_T3'] = pd.to_numeric(eeg_df['O1_T3'], errors='coerce')\n",
    "    eeg_df['O2_T4'] = pd.to_numeric(eeg_df['O2_T4'], errors='coerce')\n",
    "\n",
    "    start_time = datetime.strptime(EEG_UTCStartTime, \"%Y-%m-%d %H:%M:%S\")\n",
    "    timestamps = [start_time + timedelta(seconds=MeasuringIntervalInSeconds * i) for i in range(len(eeg_df))]\n",
    "    eeg_df['Timestamp'] = timestamps\n",
    "\n",
    "    eeg_df = eeg_df[:100]\n",
    "\n",
    "    #print(eeg_df)\n",
    "\n",
    "    spectrumController = SpectrumController()\n",
    "\n",
    "    # Create empty lists to store results per row\n",
    "    spectrum_results = defaultdict(list)  # e.g., {'O1': [...], 'O2': [...]}\n",
    "    waves_results = defaultdict(lambda: defaultdict(list))  # e.g., {'O1': {'delta_raw': [...], ...}, ...}\n",
    "\n",
    "    count = 0\n",
    "\n",
    "    def __processed_spectrum(spectrum, channel):\n",
    "        #print(count)\n",
    "        spectrum_results[channel].append(spectrum)\n",
    "\n",
    "    def __processed_waves(waves_data, channel):\n",
    "        #print(count)\n",
    "        for attr, value in waves_data.__dict__.items():\n",
    "            waves_results[channel][attr].append(value)\n",
    "\n",
    "\n",
    "    for _, row in eeg_df.iterrows():\n",
    "        single_row_df = pd.DataFrame([row])  # Wrap row in a DataFrame\n",
    "\n",
    "        # Assign callbacks\n",
    "        spectrumController.processedSpectrum = __processed_spectrum\n",
    "        spectrumController.processedWaves = __processed_waves\n",
    "\n",
    "        # Process the row\n",
    "        spectrumController.process_data(single_row_df)\n",
    "\n",
    "        count += 1\n",
    "\n",
    "    # Add spectrum results\n",
    "    #for channel in ['O1', 'O2', 'T3', 'T4']:\n",
    "    #    eeg_df[f'{channel}_spectrum'] = spectrum_results[channel]\n",
    "\n",
    "    # Add waves results\n",
    "    #for channel in ['O1', 'O2', 'T3', 'T4']:\n",
    "    #    for wave_attr in waves_results[channel]:\n",
    "    #        col_name = f'{channel}_{wave_attr}'\n",
    "    #        eeg_df[col_name] = waves_results[channel][wave_attr]\n",
    "\n",
    "    start_time = datetime.strptime(EEG_UTCStartTime, \"%Y-%m-%d %H:%M:%S\") + timedelta(seconds=MeasuringIntervalInSeconds)\n",
    "    timestamps = [start_time + timedelta(seconds=MeasuringIntervalInSeconds * i) for i in range(len(waves_results))]\n",
    "    waves_results['Timestamp'] = timestamps\n",
    "\n",
    "    spectrumController.clear()\n",
    "\n",
    "    print(waves_results)\n",
    "\n",
    "    print(f'EEG Data Length: {len(eeg_df)}')\n",
    "    print('Spectrum length:')\n",
    "    print({channel: len(values) for channel, values in spectrum_results.items()})\n",
    "    print('Wave length:')\n",
    "    print({\n",
    "        channel: {wave_type: len(values) for wave_type, values in wave_dict.items()}\n",
    "        for channel, wave_dict in waves_results.items()\n",
    "    })\n",
    "\n",
    "    # Set up wave bands and channels\n",
    "    wave_bands = ['delta_rel', 'theta_rel', 'alpha_rel', 'beta_rel', 'gamma_rel']\n",
    "    channels = ['O1', 'O2', 'T3', 'T4']\n",
    "\n",
    "    # Create subplots\n",
    "    fig, axes = plt.subplots(nrows=4, ncols=1, figsize=(14, 10), sharex=True)\n",
    "    fig.suptitle(\"Relative EEG Wave Composition Over Time\", fontsize=16)\n",
    "\n",
    "    # Plot each channel\n",
    "    for i, channel in enumerate(channels):\n",
    "        ax = axes[i]\n",
    "        \n",
    "        # Extract wave data for this channel\n",
    "        stacked_data = eeg_df[[f'{channel}_{band}' for band in wave_bands]]\n",
    "        \n",
    "        # Plot stacked area chart\n",
    "        ax.stackplot(eeg_df['Timestamp'], stacked_data.T, labels=wave_bands)\n",
    "        ax.set_ylabel(channel)\n",
    "        ax.legend(loc='upper right', fontsize=8)\n",
    "        ax.grid(True)\n",
    "\n",
    "    # Final touches\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
